---
name: benchmark-analysis
description: Run and analyze Go benchmarks, compare performance metrics, and validate optimizations. Use when measuring performance improvements, detecting regressions, or establishing performance baselines.
allowed-tools: Bash, Read, Grep
---

# Benchmark Analysis Skill

You are an expert in Go benchmarking and performance analysis with deep knowledge of:
- `go test -bench` framework
- `benchstat` for statistical analysis
- Performance measurement best practices
- Regression detection
- Benchmark design patterns

## Core Principles

1. **Statistical Significance Matters**
   - Run benchmarks multiple times (â‰¥10)
   - Use `benchstat` to validate improvements
   - Account for measurement variance
   - Warm up before measuring

2. **Realistic Workloads**
   - Benchmark real-world scenarios
   - Use representative data sizes
   - Include cold and warm cache states
   - Measure end-to-end, not just units

3. **Comprehensive Metrics**
   - ns/op (latency)
   - ops/sec (throughput)
   - B/op (bytes allocated per operation)
   - allocs/op (allocations per operation)
   - MB/s (throughput for I/O operations)

## Benchmarking Workflow

### Step 1: Design Benchmark

```go
// Good benchmark structure
func BenchmarkHTTP11Parser(b *testing.B) {
    data := []byte("GET /index.html HTTP/1.1\r\n" +
                   "Host: example.com\r\n" +
                   "User-Agent: bench\r\n\r\n")

    b.ResetTimer() // Don't measure setup
    b.ReportAllocs() // Include allocation metrics

    for i := 0; i < b.N; i++ {
        req, err := ParseRequest(bytes.NewReader(data))
        if err != nil {
            b.Fatal(err)
        }
        _ = req // Prevent compiler optimization
    }
}
```

### Step 2: Run Baseline

```bash
# Capture baseline on main branch
git checkout main
go test -bench=. -benchmem -count=10 > baseline.txt

# Review results
cat baseline.txt
```

### Step 3: Run After Changes

```bash
# Test your optimization
git checkout feature/optimization
go test -bench=. -benchmem -count=10 > optimized.txt
```

### Step 4: Statistical Comparison

```bash
# Install benchstat if needed
go install golang.org/x/perf/cmd/benchstat@latest

# Compare
benchstat baseline.txt optimized.txt

# Output shows:
# - Mean improvement
# - Statistical significance (p-value)
# - Confidence interval
```

## Benchmark Patterns

### Pattern 1: Parser Benchmarks

```go
func BenchmarkParseRequest(b *testing.B) {
    testCases := []struct{
        name string
        data []byte
    }{
        {"simple", []byte("GET / HTTP/1.1\r\n\r\n")},
        {"with-headers", makeRequestWithHeaders(10)},
        {"large-headers", makeRequestWithHeaders(32)},
    }

    for _, tc := range testCases {
        b.Run(tc.name, func(b *testing.B) {
            b.ReportAllocs()
            b.SetBytes(int64(len(tc.data)))

            for i := 0; i < b.N; i++ {
                _, err := ParseRequest(bytes.NewReader(tc.data))
                if err != nil {
                    b.Fatal(err)
                }
            }
        })
    }
}
```

### Pattern 2: Throughput Benchmarks

```go
func BenchmarkServerThroughput(b *testing.B) {
    server := NewServer()
    defer server.Close()

    b.RunParallel(func(pb *testing.PB) {
        client := &http.Client{}
        for pb.Next() {
            resp, err := client.Get(server.URL)
            if err != nil {
                b.Fatal(err)
            }
            io.Copy(io.Discard, resp.Body)
            resp.Body.Close()
        }
    })
}
```

### Pattern 3: Allocation Benchmarks

```go
func BenchmarkZeroAlloc(b *testing.B) {
    var req Request
    data := []byte("GET / HTTP/1.1\r\n\r\n")

    b.ReportAllocs()
    b.ResetTimer()

    for i := 0; i < b.N; i++ {
        req.Reset() // Reuse
        err := req.Parse(bytes.NewReader(data))
        if err != nil {
            b.Fatal(err)
        }
    }

    // Verify zero allocations
    if got := testing.AllocsPerRun(100, func() {
        req.Reset()
        req.Parse(bytes.NewReader(data))
    }); got > 0 {
        b.Errorf("expected 0 allocs, got %v", got)
    }
}
```

### Pattern 4: Comparison Benchmarks

```go
func BenchmarkShockwaveVsNetHTTP(b *testing.B) {
    b.Run("shockwave", func(b *testing.B) {
        // Shockwave implementation
    })

    b.Run("net/http", func(b *testing.B) {
        // Standard library implementation
    })
}
```

## Benchmark Execution Strategies

### Quick Check (Development)

```bash
# Single run, sanity check
go test -bench=BenchmarkFoo -benchtime=1s
```

### Thorough Analysis (Pre-commit)

```bash
# Multiple runs with statistical analysis
go test -bench=. -benchmem -count=10 -benchtime=3s > results.txt
benchstat results.txt
```

### Regression Testing (CI)

```bash
# Compare against main branch
git checkout main
go test -bench=. -benchmem -count=10 > main.txt

git checkout feature-branch
go test -bench=. -benchmem -count=10 > feature.txt

benchstat main.txt feature.txt

# Fail CI if regression >5%
```

### Long-Running Stability

```bash
# Extended run to catch memory leaks or degradation
go test -bench=BenchmarkServer -benchtime=60s -timeout=10m
```

## Performance Targets (Shockwave)

### HTTP/1.1 Parser
```
BenchmarkParseRequest/simple-8
  Target: >10M ops/sec, 0 allocs/op
  Acceptable: >5M ops/sec, 0 allocs/op
```

### Keep-Alive Handling
```
BenchmarkKeepAlive-8
  Target: 0 allocs/op
  Acceptable: 0 allocs/op (non-negotiable)
```

### Response Writing
```
BenchmarkWriteResponse-8
  Target: >1M ops/sec, 0 allocs/op for status line
  Acceptable: >500K ops/sec, 0 allocs/op
```

### HTTP/2 Multiplexing
```
BenchmarkHTTP2Concurrent-8
  Target: >300K req/sec (concurrent streams)
  Acceptable: >200K req/sec
```

## Regression Detection

### Acceptable Thresholds

- **Latency (ns/op)**: Max 5% regression
- **Throughput (ops/sec)**: Max 5% regression
- **Allocations (allocs/op)**: No regression (0 must stay 0)
- **Memory (B/op)**: Max 10% regression

### Using benchstat

```bash
benchstat baseline.txt current.txt

# Look for:
# - ~ symbol (no significant change)
# - + symbol (improvement)
# - - symbol (regression)
# - p-value <0.05 (statistically significant)
```

### Example Output Analysis

```
name                old time/op  new time/op  delta
ParseRequest-8      156ns Â± 2%   98ns Â± 1%   -37.18%  (p=0.000 n=10+10)
WriteResponse-8     89ns Â± 1%    91ns Â± 2%     +2.25%  (p=0.041 n=10+10)

name                old alloc/op new alloc/op delta
ParseRequest-8      0.00B        0.00B          ~     (all equal)
WriteResponse-8     0.00B        48.0B Â± 0%     +Inf%  (p=0.000 n=10+10)
```

**Analysis:**
- âœ… ParseRequest: 37% faster, great improvement
- âš ï¸  WriteResponse: 2.25% slower, within threshold but investigate
- âŒ WriteResponse: New allocations introduced, MUST FIX

## Benchmark Profiling

### CPU Profile from Benchmark

```bash
# Generate CPU profile
go test -bench=BenchmarkHTTP11 -cpuprofile=cpu.prof

# Analyze
go tool pprof -http=:8080 cpu.prof
```

### Memory Profile from Benchmark

```bash
# Generate memory profile
go test -bench=BenchmarkHTTP11 -memprofile=mem.prof

# Analyze allocations
go tool pprof -alloc_space mem.prof
```

### Trace Analysis

```bash
# Generate execution trace
go test -bench=BenchmarkHTTP11 -trace=trace.out

# View in browser
go tool trace trace.out
```

## Continuous Benchmarking

### Benchmark Suite Script

Create `scripts/bench_suite.sh`:
```bash
#!/bin/bash
set -e

echo "Running comprehensive benchmark suite..."

# Core benchmarks
echo "=== HTTP/1.1 Parser ==="
go test -bench=BenchmarkHTTP11Parser -benchmem -count=10

echo "=== HTTP/2 Multiplexing ==="
go test -bench=BenchmarkHTTP2 -benchmem -count=10

echo "=== WebSocket ==="
go test -bench=BenchmarkWebSocket -benchmem -count=10

echo "=== Memory Pools ==="
go test -bench=BenchmarkPool -benchmem -count=10

# With different build tags
echo "=== Arena Allocation ==="
GOEXPERIMENT=arenas go test -tags=arenas -bench=. -benchmem -count=5

echo "=== Green Tea GC ==="
go test -tags=greenteagc -bench=. -benchmem -count=5
```

### Regression Test Script

Create `scripts/check_regression.sh`:
```bash
#!/bin/bash
set -e

# Capture baseline
git stash
git checkout main
go test -bench=. -benchmem -count=10 > /tmp/baseline.txt

# Test current changes
git checkout -
git stash pop || true
go test -bench=. -benchmem -count=10 > /tmp/current.txt

# Compare
benchstat /tmp/baseline.txt /tmp/current.txt > /tmp/comparison.txt

# Check for regressions
if grep -E "~|\+" /tmp/comparison.txt > /dev/null; then
    echo "âœ“ No significant regressions detected"
    cat /tmp/comparison.txt
    exit 0
else
    echo "âœ— Performance regression detected!"
    cat /tmp/comparison.txt
    exit 1
fi
```

## Benchmark Best Practices

### âœ… Do This

1. **Reset timer after setup**
   ```go
   b.ResetTimer()
   ```

2. **Report allocations**
   ```go
   b.ReportAllocs()
   ```

3. **Prevent compiler optimizations**
   ```go
   var result *Request
   for i := 0; i < b.N; i++ {
       result, _ = ParseRequest(data)
   }
   _ = result // Use the result
   ```

4. **Use representative data sizes**
   ```go
   b.SetBytes(int64(len(data))) // For throughput calculation
   ```

5. **Run multiple iterations**
   ```bash
   go test -bench=. -count=10
   ```

### âŒ Don't Do This

1. **Benchmark setup in loop**
   ```go
   for i := 0; i < b.N; i++ {
       data := makeData() // BAD: measured every iteration
       process(data)
   }
   ```

2. **Ignore warmup**
   ```go
   // BAD: First iteration is cold
   b.ResetTimer()
   ```

3. **Use tiny benchtime**
   ```bash
   go test -bench=. -benchtime=10ms # Too short, high variance
   ```

4. **Forget to use results**
   ```go
   for i := 0; i < b.N; i++ {
       ParseRequest(data) // Compiler might optimize away
   }
   ```

## Output Format

When completing benchmark analysis, provide:

```markdown
## Benchmark Analysis Report

### Benchmarks Run
- Package: [package name]
- Date: [timestamp]
- Commit: [git hash]
- Build tags: [tags used]

### Results Summary
| Benchmark | ns/op | B/op | allocs/op | Î” from baseline |
|-----------|-------|------|-----------|-----------------|
| BenchmarkFoo | 123 | 0 | 0 | +25% ðŸŽ‰ |
| BenchmarkBar | 456 | 48 | 1 | -5% âš ï¸  |

### Statistical Significance
- Runs: 10
- benchstat p-value: <0.05
- Confidence: 95%

### Performance Analysis
1. **BenchmarkFoo: +25% improvement**
   - Root cause: [optimization applied]
   - Allocation reduction: [before â†’ after]

2. **BenchmarkBar: -5% regression**
   - Within acceptable threshold
   - Caused by: [trade-off explanation]

### Recommendations
- [ ] Merge: Performance improved
- [ ] Investigate: BenchmarkBar regression
- [ ] Profile: Deep dive into hot paths
```

## References

- Benchmark Design: context/benchmark-guide.md
- benchstat: https://pkg.go.dev/golang.org/x/perf/cmd/benchstat
